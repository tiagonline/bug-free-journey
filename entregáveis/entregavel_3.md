### 3.1. Indicadores de Qualidade (KPIs)

Minha proposta de KPIs foca em dois pilares: **M√©tricas de Resultado (Outcome)**, que medem o impacto no neg√≥cio, e **M√©tricas de Processo (Output)**, que ajudam no diagn√≥stico di√°rio.

#### A. M√©tricas de Resultado (Foco Principal: DORA)

Para uma vis√£o moderna e acion√°vel, o foco principal deve ser nas **M√©tricas DORA (Four Key Metrics)** (conforme a [refer√™ncia oficial do Google Cloud](https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance)), que implementei na minha experi√™ncia como QA Tech Lead na Zak. Foi uma a√ß√£o conjunta entre o time de QA, Desenvolvimento e Infra.

1.  **Lead Time for Changes (LTFC):** √â o tempo entre o *commit* de uma corre√ß√£o no m√≥dulo "Documentos" e o *deploy* em produ√ß√£o. (Mede a efici√™ncia do pipeline).
2.  **Deployment Frequency (DF):** Com que frequ√™ncia fazemos deploy deste m√≥dulo. (Mede a agilidade).
3.  **Change Failure Rate (CFR):** (A "taxa de falhas" solicitada). Quantos *deploys* deste m√≥dulo resultam em *hotfix*? (Mede a estabilidade).
4.  **Time to Restore Service (TTRS):** (O "tempo de corre√ß√£o" solicitado). Se o servi√ßo de OCR cair, quanto tempo levamos para restaurar o servi√ßo? (Mede a resili√™ncia).

#### B. M√©tricas de Processo (Diagn√≥stico e Performance)

Estas s√£o m√©tricas mais tradicionais (comumente usadas) que d√£o suporte √† an√°lise de causa-raiz das M√©tricas DORA.

5.  **Taxa de Fuga de Defeitos (Defect Escape Rate):** A m√©trica tradicional mais importante. Compara o n¬∫ de bugs encontrados em Produ√ß√£o (pelo cliente/suporte) vs. o n¬∫ de bugs encontrados em Homologa√ß√£o (pelo time de QA). *√â acion√°vel:* Se a taxa de fuga √© alta, nosso processo de QA (Entreg√°vel 1) falhou.
6.  **Tempo de Resposta P95 (K6):** (A "performance" solicitada). O tempo de resposta para 95% das requisi√ß√µes de upload sob carga. *√â acion√°vel:* Se o P95 est√° acima do SLA, sabemos que o OCR s√≠ncrono √© o gargalo.
7.  **Taxa de Erro (K6 Error Rate):** Percentual de falhas nos uploads sob carga.
8.  **Cobertura de Testes (Code Coverage):** (A "cobertura"). O percentual do c√≥digo coberto por testes (Unit√°rios, API, etc.). *√â uma m√©trica de suporte, n√£o de vaidade.* Uma baixa cobertura em √°reas cr√≠ticas (como o *retry* do OCR) √© um *risco* que deve ser priorizado. Outro ponto √© que nem sempre altas coberturas significam boa qualidade de testes.


### 3.2. Simula√ß√£o de Relat√≥rio (Dashboard Acion√°vel)

O "relat√≥rio simulado" n√£o deve ser um documento est√°tico (como esta tabela), mas sim um **dashboard de observabilidade em tempo real**. Uso aqui o Grafana.

Como demonstro no meu projeto [qa-k6-with-grafana](https://github.com/tiagonline/qa-k6-with-grafana), a melhor pr√°tica √© usar o **K6** para enviar m√©tricas de execu√ß√£o (Taxa de Erro, P95) diretamente para um *dashboard* no **Grafana**.

**Relat√≥rio Fict√≠cio (Exemplo de Dashboard):**
* **Painel 1 (Qualidade do Deploy):** Change Failure Rate (CFR): 35% üî¥
* **Painel 2 (Resili√™ncia):** Time to Restore (TTRS): 4 horas üü°
* **Painel 3 (Performance da API de Upload - K6/Grafana):**
    * Taxa de Erro (5 min): 8% üî¥
    * Tempo de Resposta P95 (5 min): 3500ms üü°

### 3.3. M√©tricas Acion√°veis (Tomada de Decis√£o com o time Produtos)

As m√©tricas acima (do Grafana e do DORA) n√£o s√£o apenas n√∫meros, elas s√£o **acion√°veis** e d√£o suporte √† melhoria cont√≠nua.

Elas fornecem **dados objetivos** que direcionam o time a focar na **causa-raiz (o processo)**, em vez de procurar culpados individuais. A conversa muda de "Quem falhou? / O QA deixou passar!" para "O que no nosso processo falhou?".

* **Cen√°rio 1 (CFR Alto):** "PM identifica que o **Change Failure Rate est√° em 35%** üî¥. Os dados mostram que as falhas v√™m da integra√ß√£o com o OCR. Isso √© **acion√°vel**. Precisa pausar a 'feature xpto' e alocar uma *sprint* para estabilizar essa integra√ß√£o (Testes de Contrato/Mocks), sen√£o continuar√° com falhas em produ√ß√£o."

* **Cen√°rio 2 (Performance Ruim - K6/Grafana):** "O dashboard do Grafana mostra que o **P95 est√° em 3500ms** üü°, acima do SLA, e a **Taxa de Erro est√° em 8%** üî¥. O gargalo √© o OCR s√≠ncrono. Isso √© **acion√°vel**. Precisamos priorizar uma *task* para otimizar essa chamada ou torn√°-la *ass√≠ncrona*."




